{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "790be32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from functools import partial\n",
    "\n",
    "import net\n",
    "from hyptorch.pmath import dist_matrix\n",
    "from proxy_anchor import dataset\n",
    "from proxy_anchor.utils import calc_recall_at_k\n",
    "from sampler import UniqueClassSempler\n",
    "from proxy_anchor.dataset import CUBirds, SOP, Cars\n",
    "from proxy_anchor.dataset.Inshop import Inshop_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d3f9bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65eb4af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/data/xuyunhao/datasets'\n",
    "ds = 'CUB'\n",
    "num_samples = 2\n",
    "bs = 200\n",
    "lr = 1e-5\n",
    "t = 0.2\n",
    "emb = 512\n",
    "ep = 100\n",
    "local_rank = 0\n",
    "workers = 4\n",
    "optimizer = 'adamw'\n",
    "lr_decay_step = 10\n",
    "lr_decay_gamma = 0.5\n",
    "\n",
    "model =  'resnet34'\n",
    "hyp_c = 0\n",
    "clip_r  = 2.3\n",
    "resize = 224\n",
    "crop = 224\n",
    "gpu_id = 5\n",
    "bn_freeze = 1\n",
    "freezer = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d687294",
   "metadata": {},
   "source": [
    "# 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7c1f278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(e0, e1, tau):\n",
    "    # x0 and x1 - positive pair\n",
    "    # tau - temperature\n",
    "    # hyp_c - hyperbolic curvature, \"0\" enables sphere mode\n",
    "    dist_e = lambda x, y: -torch.cdist(x, y, p=2)\n",
    "    \n",
    "    dist_e0 = dist_e(e0, e0)   \n",
    "    dist_e1 = dist_e(e0, e1)\n",
    "\n",
    "    bsize = e0.shape[0]\n",
    "    target = torch.arange(bsize).cuda()\n",
    "    eye_mask = torch.eye(bsize).cuda() * 1e9\n",
    "    \n",
    "    logits00 = dist_e0 / tau - eye_mask\n",
    "    logits01 = dist_e1 / tau\n",
    "    \n",
    "    logits = torch.cat([logits01, logits00], dim=1)\n",
    "    logits -= logits.max(1, keepdim=True)[0].detach()\n",
    "    loss = F.cross_entropy(logits, target)\n",
    "    stats = {\n",
    "        \"logits/min\": logits01.min().item(),\n",
    "        \"logits/mean\": logits01.mean().item(),\n",
    "        \"logits/max\": logits01.max().item(),\n",
    "        \"logits/acc\": (logits01.argmax(-1) == target).float().mean().item(),\n",
    "    }\n",
    "    return loss, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc6c41a",
   "metadata": {},
   "source": [
    "# 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aca920c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.init as init\n",
    "import hyptorch.nn as hypnn\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.models import resnet34\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.models import resnet101"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c55ad3a",
   "metadata": {},
   "source": [
    "## resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d7b1306",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet18(nn.Module):\n",
    "    def __init__(self,embedding_size, pretrained=True, bn_freeze = True):\n",
    "        super(Resnet18, self).__init__()\n",
    "\n",
    "        self.model = resnet18(pretrained)\n",
    "        self.embedding_size = embedding_size\n",
    "        self.num_ftrs = self.model.fc.in_features\n",
    "        self.model.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.model.gmp = nn.AdaptiveMaxPool2d(1)\n",
    "        \n",
    "        self.Elayer = NormLayer()\n",
    "        self.model.embedding = nn.Sequential(nn.Linear(self.num_ftrs, self.embedding_size), self.Elayer)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "        if bn_freeze:\n",
    "            for m in self.model.modules():\n",
    "                if isinstance(m, nn.BatchNorm2d):\n",
    "                    m.eval()\n",
    "                    m.weight.requires_grad_(False)\n",
    "                    m.bias.requires_grad_(False)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.conv1(x)\n",
    "        x = self.model.bn1(x)\n",
    "        x = self.model.relu(x)\n",
    "        x = self.model.maxpool(x)\n",
    "        x = self.model.layer1(x)\n",
    "        x = self.model.layer2(x)\n",
    "        x = self.model.layer3(x)\n",
    "        x = self.model.layer4(x)\n",
    "\n",
    "        avg_x = self.model.gap(x)\n",
    "        max_x = self.model.gmp(x)\n",
    "\n",
    "        x = max_x + avg_x\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x_e = self.model.embedding(x)\n",
    "        return x_e\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        init.kaiming_normal_(self.model.embedding[0].weight, mode='fan_out')\n",
    "        init.constant_(self.model.embedding[0].bias, 0)\n",
    "\n",
    "class NormLayer(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return F.normalize(x, p=2, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac31244",
   "metadata": {},
   "source": [
    "# resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7becf075",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet34(nn.Module):\n",
    "    def __init__(self,embedding_size, pretrained=True, bn_freeze = True):\n",
    "        super(Resnet34, self).__init__()\n",
    "\n",
    "        self.model = resnet34(pretrained)\n",
    "        self.embedding_size = embedding_size\n",
    "        self.num_ftrs = self.model.fc.in_features\n",
    "        self.model.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.model.gmp = nn.AdaptiveMaxPool2d(1)\n",
    "        \n",
    "        self.Elayer = NormLayer()\n",
    "        self.model.embedding = nn.Sequential(nn.Linear(self.num_ftrs, self.embedding_size), self.Elayer)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "        if bn_freeze:\n",
    "            for m in self.model.modules():\n",
    "                if isinstance(m, nn.BatchNorm2d):\n",
    "                    m.eval()\n",
    "                    m.weight.requires_grad_(False)\n",
    "                    m.bias.requires_grad_(False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.conv1(x)\n",
    "        x = self.model.bn1(x)\n",
    "        x = self.model.relu(x)\n",
    "        x = self.model.maxpool(x)\n",
    "        x = self.model.layer1(x)\n",
    "        x = self.model.layer2(x)\n",
    "        x = self.model.layer3(x)\n",
    "        x = self.model.layer4(x)\n",
    "\n",
    "        avg_x = self.model.gap(x)\n",
    "        max_x = self.model.gmp(x)\n",
    "\n",
    "        x = avg_x + max_x\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x_e = self.model.embedding(x)\n",
    "        return x_e\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        init.kaiming_normal_(self.model.embedding[0].weight, mode='fan_out')\n",
    "        init.constant_(self.model.embedding[0].bias, 0)\n",
    "\n",
    "class NormLayer(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return F.normalize(x, p=2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbf9d02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(get_emb_f, ds_name):\n",
    "    emb_head = get_emb_f(ds_type=\"eval\")\n",
    "    recall_head = get_recall(*emb_head, ds_name)\n",
    "    return recall_head\n",
    "\n",
    "def get_recall(e, y, ds_name):\n",
    "    if ds_name == \"CUB\" or ds_name == \"Cars\":\n",
    "        k_list = [1, 2, 4, 8, 16, 32]\n",
    "    elif ds_name == \"SOP\":\n",
    "        k_list = [1, 10, 100, 1000]\n",
    "\n",
    "    dist_m = torch.empty(len(e), len(e), device=\"cuda\")\n",
    "    for i in range(len(e)):\n",
    "        dist_m[i : i + 1] = -torch.cdist(e[i : i + 1], e, p=2)\n",
    "\n",
    "    y_cur = y[dist_m.topk(1 + max(k_list), largest=True)[1][:, 1:]]\n",
    "    y = y.cpu()\n",
    "    y_cur = y_cur.float().cpu()\n",
    "    recall = [calc_recall_at_k(y, y_cur, k) for k in k_list]\n",
    "    print(recall)\n",
    "    return recall[0]\n",
    "\n",
    "def get_emb(\n",
    "    model,\n",
    "    ds,\n",
    "    path,\n",
    "    ds_type=\"eval\",\n",
    "    world_size=1,\n",
    "    num_workers=8,\n",
    "):\n",
    "    eval_tr = dataset.utils.make_transform(\n",
    "        is_train = True, \n",
    "        is_inception = (model == 'bn_inception')\n",
    "    )\n",
    "    ds_eval = ds(path, ds_type, eval_tr)\n",
    "    if world_size == 1:\n",
    "        sampler = None\n",
    "    else:\n",
    "        sampler = torch.utils.data.distributed.DistributedSampler(ds_eval)\n",
    "    dl_eval = DataLoader(\n",
    "        dataset=ds_eval,\n",
    "        batch_size=100,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        sampler=sampler,\n",
    "    )\n",
    "    model.eval()\n",
    "    e, y = eval_dataset(model, dl_eval)\n",
    "    y = y.cuda()\n",
    "    model.train()\n",
    "    return e, y\n",
    "\n",
    "def eval_dataset(model, dl):\n",
    "    all_xe, all_y = [], []\n",
    "    for x, y in dl:\n",
    "        with torch.no_grad():\n",
    "            x = x.cuda(non_blocking=True)\n",
    "            e= model(x)\n",
    "            all_xe.append(e)\n",
    "        all_y.append(y)\n",
    "    return torch.cat(all_xe), torch.cat(all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7a0c638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 100 epochs.\n",
      "[0.4176232275489534, 0.5406819716407832, 0.6561444969615124, 0.762322754895341, 0.8529709655638082, 0.9098582039162728]\n",
      "The recall before train:  0.4176232275489534\n",
      "[0.41812964213369347, 0.5408507765023632, 0.6568197164078325, 0.7641796083727211, 0.8507765023632681, 0.9076637407157326]\n",
      "epoch: 0 recall:  0.41812964213369347\n",
      "best epoch: 0 best recall:  0.41812964213369347\n",
      "[0.4161039837947333, 0.5410195813639432, 0.6617150573936529, 0.7667116812964213, 0.849763673193788, 0.9137407157326131]\n",
      "epoch: 1 recall:  0.4161039837947333\n",
      "best epoch: 0 best recall:  0.41812964213369347\n",
      "[0.4150911546252532, 0.5401755570560433, 0.6583389601620526, 0.7721134368669818, 0.8553342336259284, 0.9144159351789332]\n",
      "epoch: 2 recall:  0.4150911546252532\n",
      "best epoch: 0 best recall:  0.41812964213369347\n",
      "[0.41188386225523294, 0.5349426063470628, 0.6580013504388926, 0.7668804861580013, 0.8561782579338285, 0.9152599594868333]\n",
      "epoch: 3 recall:  0.41188386225523294\n",
      "best epoch: 0 best recall:  0.41812964213369347\n",
      "[0.4024307900067522, 0.5285280216070223, 0.6591829844699527, 0.7667116812964213, 0.8528021607022283, 0.9152599594868333]\n",
      "epoch: 4 recall:  0.4024307900067522\n",
      "best epoch: 0 best recall:  0.41812964213369347\n",
      "[0.39888588791357193, 0.5214382174206618, 0.6450033760972316, 0.7574274139095206, 0.8482444294395679, 0.9105334233625928]\n",
      "epoch: 5 recall:  0.39888588791357193\n",
      "best epoch: 0 best recall:  0.41812964213369347\n",
      "[0.40867656988521267, 0.5361242403781229, 0.6598582039162728, 0.7673869007427414, 0.8509453072248481, 0.9162727886563133]\n",
      "epoch: 6 recall:  0.40867656988521267\n",
      "best epoch: 0 best recall:  0.41812964213369347\n",
      "[0.4208305199189737, 0.5433828494260635, 0.6667792032410533, 0.7677245104659014, 0.8533085752869682, 0.912559081701553]\n",
      "epoch: 7 recall:  0.4208305199189737\n",
      "best epoch: 7 best recall:  0.4208305199189737\n",
      "[0.40681971640783254, 0.5261647535449021, 0.6566509115462525, 0.7668804861580013, 0.8511141120864281, 0.9164415935178933]\n",
      "epoch: 8 recall:  0.40681971640783254\n",
      "best epoch: 7 best recall:  0.4208305199189737\n",
      "[0.400236326806212, 0.5297096556380824, 0.6544564483457124, 0.7601282916948008, 0.8479068197164078, 0.9098582039162728]\n",
      "epoch: 9 recall:  0.400236326806212\n",
      "best epoch: 7 best recall:  0.4208305199189737\n",
      "[0.4012491559756921, 0.5275151924375422, 0.6465226198514518, 0.7547265361242403, 0.8446995273463875, 0.9056380823767725]\n",
      "epoch: 10 recall:  0.4012491559756921\n",
      "best epoch: 7 best recall:  0.4208305199189737\n",
      "[0.4149223497636732, 0.5410195813639432, 0.6541188386225524, 0.7670492910195814, 0.8543214044564483, 0.9108710330857529]\n",
      "epoch: 11 recall:  0.4149223497636732\n",
      "best epoch: 7 best recall:  0.4208305199189737\n",
      "[0.4216745442268737, 0.5403443619176233, 0.6590141796083727, 0.7648548278190412, 0.8521269412559082, 0.9110398379473329]\n",
      "epoch: 12 recall:  0.4216745442268737\n",
      "best epoch: 12 best recall:  0.4216745442268737\n",
      "[0.4063133018230925, 0.5297096556380824, 0.6520931802835922, 0.761647535449021, 0.8453747467927076, 0.911883862255233]\n",
      "epoch: 13 recall:  0.4063133018230925\n",
      "best epoch: 12 best recall:  0.4216745442268737\n",
      "[0.4100270087778528, 0.5320729237002025, 0.6495611073598919, 0.7569209993247805, 0.8404794058068873, 0.9080013504388926]\n",
      "epoch: 14 recall:  0.4100270087778528\n",
      "best epoch: 12 best recall:  0.4216745442268737\n",
      "[0.4139095205941931, 0.5359554355165429, 0.6524307900067522, 0.7638419986495611, 0.8531397704253882, 0.9142471303173532]\n",
      "epoch: 15 recall:  0.4139095205941931\n",
      "best epoch: 12 best recall:  0.4216745442268737\n",
      "[0.41458474004051316, 0.537474679270763, 0.6590141796083727, 0.7628291694800811, 0.8511141120864281, 0.912559081701553]\n",
      "epoch: 16 recall:  0.41458474004051316\n",
      "best epoch: 12 best recall:  0.4216745442268737\n",
      "[0.41745442268737337, 0.5366306549628629, 0.6558068872383525, 0.7677245104659014, 0.8504388926401081, 0.9150911546252533]\n",
      "epoch: 17 recall:  0.41745442268737337\n",
      "best epoch: 12 best recall:  0.4216745442268737\n",
      "[0.4147535449020932, 0.5393315327481432, 0.6578325455773126, 0.7727886563133018, 0.8565158676569885, 0.9139095205941931]\n",
      "epoch: 18 recall:  0.4147535449020932\n",
      "best epoch: 12 best recall:  0.4216745442268737\n",
      "[0.41559756920999325, 0.537474679270763, 0.6628966914247131, 0.7677245104659014, 0.8516205266711682, 0.9117150573936529]\n",
      "epoch: 19 recall:  0.41559756920999325\n",
      "best epoch: 12 best recall:  0.4216745442268737\n",
      "[0.40800135043889263, 0.5275151924375422, 0.6482106684672518, 0.7586090479405807, 0.8453747467927076, 0.9140783254557732]\n",
      "epoch: 20 recall:  0.40800135043889263\n",
      "best epoch: 12 best recall:  0.4216745442268737\n",
      "[0.40276839972991224, 0.5278528021607022, 0.6536124240378123, 0.7604659014179609, 0.8487508440243079, 0.912390276839973]\n",
      "epoch: 21 recall:  0.40276839972991224\n",
      "best epoch: 12 best recall:  0.4216745442268737\n",
      "[0.40665091154625255, 0.5310600945307224, 0.6573261309925725, 0.7658676569885212, 0.850270087778528, 0.9128966914247131]\n",
      "epoch: 22 recall:  0.40665091154625255\n",
      "best epoch: 12 best recall:  0.4216745442268737\n",
      "[0.41154625253207294, 0.537812288993923, 0.6510803511141121, 0.7493247805536799, 0.8430114787305875, 0.9074949358541526]\n",
      "epoch: 23 recall:  0.41154625253207294\n",
      "best epoch: 12 best recall:  0.4216745442268737\n",
      "[0.41644159351789334, 0.5410195813639432, 0.661883862255233, 0.7672180958811614, 0.8538149898717083, 0.9159351789331532]\n",
      "epoch: 24 recall:  0.41644159351789334\n",
      "best epoch: 12 best recall:  0.4216745442268737\n",
      "[0.40209318028359214, 0.5332545577312626, 0.6554692775151925, 0.7724510465901417, 0.8570222822417286, 0.9134031060094531]\n",
      "epoch: 25 recall:  0.40209318028359214\n",
      "best epoch: 12 best recall:  0.4216745442268737\n",
      "[0.40276839972991224, 0.5261647535449021, 0.6466914247130318, 0.7567521944632005, 0.8423362592842674, 0.9112086428089129]\n",
      "epoch: 26 recall:  0.40276839972991224\n",
      "best epoch: 12 best recall:  0.4216745442268737\n",
      "[0.4064821066846725, 0.5261647535449021, 0.6419648885887913, 0.7535449020931803, 0.849426063470628, 0.9083389601620526]\n",
      "epoch: 27 recall:  0.4064821066846725\n",
      "best epoch: 12 best recall:  0.4216745442268737\n",
      "[0.413065496286293, 0.5319041188386225, 0.650742741390952, 0.7591154625253207, 0.8463875759621877, 0.9095205941931127]\n",
      "epoch: 28 recall:  0.413065496286293\n",
      "best epoch: 12 best recall:  0.4216745442268737\n",
      "[0.4169480081026334, 0.5342673869007427, 0.6480418636056718, 0.7533760972316003, 0.8425050641458474, 0.911883862255233]\n",
      "epoch: 29 recall:  0.4169480081026334\n",
      "best epoch: 12 best recall:  0.4216745442268737\n",
      "[0.39888588791357193, 0.5275151924375422, 0.6515867656988521, 0.7555705604321404, 0.8438555030384876, 0.9049628629304524]\n",
      "epoch: 30 recall:  0.39888588791357193\n",
      "best epoch: 12 best recall:  0.4216745442268737\n",
      "[0.40276839972991224, 0.5300472653612424, 0.6524307900067522, 0.7604659014179609, 0.8445307224848075, 0.9091829844699527]\n",
      "epoch: 31 recall:  0.40276839972991224\n",
      "best epoch: 12 best recall:  0.4216745442268737\n",
      "[0.41458474004051316, 0.5455773126266037, 0.6661039837947332, 0.7685685347738015, 0.8490884537474679, 0.9098582039162728]\n",
      "epoch: 32 recall:  0.41458474004051316\n",
      "best epoch: 12 best recall:  0.4216745442268737\n",
      "[0.400067521944632, 0.525151924375422, 0.6475354490209319, 0.7582714382174207, 0.849257258609048, 0.9117150573936529]\n",
      "epoch: 33 recall:  0.400067521944632\n",
      "best epoch: 12 best recall:  0.4216745442268737\n",
      "[0.42218095881161377, 0.5479405806887239, 0.662221471978393, 0.7678933153274814, 0.8587103308575287, 0.9174544226873734]\n",
      "epoch: 34 recall:  0.42218095881161377\n",
      "best epoch: 34 best recall:  0.42218095881161377\n",
      "[0.4063133018230925, 0.5356178257933828, 0.6546252532072924, 0.7626603646185011, 0.8445307224848075, 0.9071573261309925]\n",
      "epoch: 35 recall:  0.4063133018230925\n",
      "best epoch: 34 best recall:  0.42218095881161377\n",
      "[0.3973666441593518, 0.5236326806212019, 0.6451721809588116, 0.7543889264010804, 0.8435178933153274, 0.9167792032410533]\n",
      "epoch: 36 recall:  0.3973666441593518\n",
      "best epoch: 34 best recall:  0.42218095881161377\n",
      "[0.4091829844699527, 0.5389939230249832, 0.6586765698852127, 0.7677245104659014, 0.8529709655638082, 0.9161039837947332]\n",
      "epoch: 37 recall:  0.4091829844699527\n",
      "best epoch: 34 best recall:  0.42218095881161377\n",
      "[0.3963538149898717, 0.5265023632680621, 0.6450033760972316, 0.7613099257258609, 0.8423362592842674, 0.9059756920999325]\n",
      "epoch: 38 recall:  0.3963538149898717\n",
      "best epoch: 34 best recall:  0.42218095881161377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41644159351789334, 0.5357866306549629, 0.6635719108710331, 0.7648548278190412, 0.8436866981769074, 0.9064821066846726]\n",
      "epoch: 39 recall:  0.41644159351789334\n",
      "best epoch: 34 best recall:  0.42218095881161377\n",
      "[0.4169480081026334, 0.5351114112086428, 0.6585077650236327, 0.7609723160027009, 0.8430114787305875, 0.9061444969615124]\n",
      "epoch: 40 recall:  0.4169480081026334\n",
      "best epoch: 34 best recall:  0.42218095881161377\n",
      "[0.4112086428089129, 0.537812288993923, 0.6546252532072924, 0.7629979743416611, 0.8433490884537475, 0.9112086428089129]\n",
      "epoch: 41 recall:  0.4112086428089129\n",
      "best epoch: 34 best recall:  0.42218095881161377\n",
      "[0.40597569209993245, 0.525658338960162, 0.6485482781904118, 0.7537137069547603, 0.8438555030384876, 0.9112086428089129]\n",
      "epoch: 42 recall:  0.40597569209993245\n",
      "best epoch: 34 best recall:  0.42218095881161377\n",
      "[0.40968939905469276, 0.5322417285617825, 0.6477042538825118, 0.7552329507089804, 0.8477380148548278, 0.9107022282241729]\n",
      "epoch: 43 recall:  0.40968939905469276\n",
      "best epoch: 34 best recall:  0.42218095881161377\n",
      "[0.41424713031735316, 0.5327481431465226, 0.6608710330857529, 0.7712694125590817, 0.8553342336259284, 0.9176232275489534]\n",
      "epoch: 44 recall:  0.41424713031735316\n",
      "best epoch: 34 best recall:  0.42218095881161377\n",
      "[0.4073261309925726, 0.5320729237002025, 0.6534436191762323, 0.7604659014179609, 0.8475692099932478, 0.912221471978393]\n",
      "epoch: 45 recall:  0.4073261309925726\n",
      "best epoch: 34 best recall:  0.42218095881161377\n",
      "[0.4071573261309926, 0.5263335584064821, 0.6517555705604321, 0.7673869007427414, 0.8529709655638082, 0.912390276839973]\n",
      "epoch: 46 recall:  0.4071573261309926\n",
      "best epoch: 34 best recall:  0.42218095881161377\n",
      "[0.40310600945307223, 0.5278528021607022, 0.6514179608372721, 0.763504388926401, 0.8511141120864281, 0.9134031060094531]\n",
      "epoch: 47 recall:  0.40310600945307223\n",
      "best epoch: 34 best recall:  0.42218095881161377\n",
      "[0.40462525320729237, 0.5347738014854828, 0.6573261309925725, 0.7650236326806212, 0.8533085752869682, 0.9113774476704929]\n",
      "epoch: 48 recall:  0.40462525320729237\n",
      "best epoch: 34 best recall:  0.42218095881161377\n",
      "[0.399729912221472, 0.5300472653612424, 0.6536124240378123, 0.7685685347738015, 0.8555030384875084, 0.9098582039162728]\n",
      "epoch: 49 recall:  0.399729912221472\n",
      "best epoch: 34 best recall:  0.42218095881161377\n",
      "[0.4074949358541526, 0.5344361917623227, 0.6607022282241729, 0.7700877785280216, 0.8582039162727887, 0.9176232275489534]\n",
      "epoch: 50 recall:  0.4074949358541526\n",
      "best epoch: 34 best recall:  0.42218095881161377\n",
      "[0.40479405806887236, 0.5322417285617825, 0.6512491559756921, 0.763504388926401, 0.8504388926401081, 0.912221471978393]\n",
      "epoch: 51 recall:  0.40479405806887236\n",
      "best epoch: 34 best recall:  0.42218095881161377\n",
      "[0.40580688723835245, 0.536968264686023, 0.6601958136394328, 0.7582714382174207, 0.8455435516542876, 0.9105334233625928]\n",
      "epoch: 52 recall:  0.40580688723835245\n",
      "best epoch: 34 best recall:  0.42218095881161377\n",
      "[0.412896691424713, 0.537474679270763, 0.6537812288993923, 0.7599594868332208, 0.8404794058068873, 0.9046252532072924]\n",
      "epoch: 53 recall:  0.412896691424713\n",
      "best epoch: 34 best recall:  0.42218095881161377\n",
      "[0.40445644834571237, 0.5352802160702228, 0.6601958136394328, 0.7611411208642809, 0.8421674544226874, 0.9110398379473329]\n",
      "epoch: 54 recall:  0.40445644834571237\n",
      "best epoch: 34 best recall:  0.42218095881161377\n",
      "[0.4152599594868332, 0.5440580688723835, 0.6569885212694125, 0.761816340310601, 0.849594868332208, 0.9095205941931127]\n",
      "epoch: 55 recall:  0.4152599594868332\n",
      "best epoch: 34 best recall:  0.42218095881161377\n",
      "[0.4090141796083727, 0.5403443619176233, 0.6664415935178933, 0.7699189736664416, 0.8548278190411884, 0.9157663740715732]\n",
      "epoch: 56 recall:  0.4090141796083727\n",
      "best epoch: 34 best recall:  0.42218095881161377\n",
      "[0.40867656988521267, 0.5270087778528022, 0.6463538149898717, 0.7543889264010804, 0.837947332883187, 0.9051316677920324]\n",
      "epoch: 57 recall:  0.40867656988521267\n",
      "best epoch: 34 best recall:  0.42218095881161377\n",
      "[0.41829844699527347, 0.5410195813639432, 0.6571573261309925, 0.7653612424037812, 0.8538149898717083, 0.9108710330857529]\n",
      "epoch: 58 recall:  0.41829844699527347\n",
      "best epoch: 34 best recall:  0.42218095881161377\n",
      "[0.4176232275489534, 0.5339297771775827, 0.6585077650236327, 0.7650236326806212, 0.8487508440243079, 0.9098582039162728]\n",
      "epoch: 59 recall:  0.4176232275489534\n",
      "best epoch: 34 best recall:  0.42218095881161377\n",
      "[0.40091154625253206, 0.5292032410533424, 0.6522619851451722, 0.7678933153274814, 0.849594868332208, 0.911883862255233]\n",
      "epoch: 60 recall:  0.40091154625253206\n",
      "best epoch: 34 best recall:  0.42218095881161377\n",
      "[0.4039500337609723, 0.5344361917623227, 0.6520931802835922, 0.7643484132343011, 0.8490884537474679, 0.9100270087778528]\n",
      "epoch: 61 recall:  0.4039500337609723\n",
      "best epoch: 34 best recall:  0.42218095881161377\n",
      "[0.4139095205941931, 0.5389939230249832, 0.662559081701553, 0.7707629979743417, 0.8570222822417286, 0.912221471978393]\n",
      "epoch: 62 recall:  0.4139095205941931\n",
      "best epoch: 34 best recall:  0.42218095881161377\n",
      "[0.4149223497636732, 0.5302160702228225, 0.6480418636056718, 0.7569209993247805, 0.8462187711006077, 0.912221471978393]\n",
      "epoch: 63 recall:  0.4149223497636732\n",
      "best epoch: 34 best recall:  0.42218095881161377\n",
      "[0.4225185685347738, 0.537137069547603, 0.661883862255233, 0.7680621201890614, 0.8519581363943282, 0.9139095205941931]\n",
      "epoch: 64 recall:  0.4225185685347738\n",
      "best epoch: 64 best recall:  0.4225185685347738\n",
      "[0.4238690074274139, 0.549291019581364, 0.6654287643484132, 0.7678933153274814, 0.8524645509790681, 0.9182984469952734]\n",
      "epoch: 65 recall:  0.4238690074274139\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.40546927751519246, 0.5322417285617825, 0.6480418636056718, 0.7532072923700203, 0.8423362592842674, 0.9071573261309925]\n",
      "epoch: 66 recall:  0.40546927751519246\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.4063133018230925, 0.5351114112086428, 0.6578325455773126, 0.7683997299122215, 0.8524645509790681, 0.9100270087778528]\n",
      "epoch: 67 recall:  0.4063133018230925\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.4024307900067522, 0.5258271438217421, 0.6461850101282917, 0.7574274139095206, 0.8446995273463875, 0.912727886563133]\n",
      "epoch: 68 recall:  0.4024307900067522\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.4074949358541526, 0.5293720459149224, 0.6482106684672518, 0.7589466576637407, 0.8472316002700878, 0.9150911546252533]\n",
      "epoch: 69 recall:  0.4074949358541526\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.4177920324105334, 0.5317353139770425, 0.6539500337609723, 0.761647535449021, 0.8475692099932478, 0.9115462525320729]\n",
      "epoch: 70 recall:  0.4177920324105334\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.41441593517893316, 0.5324105334233626, 0.6537812288993923, 0.7609723160027009, 0.8475692099932478, 0.9096893990546928]\n",
      "epoch: 71 recall:  0.41441593517893316\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.41087103308575285, 0.5337609723160027, 0.650236326806212, 0.7582714382174207, 0.8482444294395679, 0.9080013504388926]\n",
      "epoch: 72 recall:  0.41087103308575285\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.400236326806212, 0.524814314652262, 0.6483794733288318, 0.7604659014179609, 0.8441931127616475, 0.9110398379473329]\n",
      "epoch: 73 recall:  0.400236326806212\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.4083389601620527, 0.5342673869007427, 0.650236326806212, 0.763673193787981, 0.8512829169480081, 0.9130654962862931]\n",
      "epoch: 74 recall:  0.4083389601620527\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.39567859554355167, 0.5241390952059419, 0.6453409858203917, 0.7587778528021607, 0.8440243079000675, 0.9101958136394328]\n",
      "epoch: 75 recall:  0.39567859554355167\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.40192437542201215, 0.5232950708980418, 0.6439905469277515, 0.7569209993247805, 0.8452059419311276, 0.9107022282241729]\n",
      "epoch: 76 recall:  0.40192437542201215\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.41661039837947333, 0.5479405806887239, 0.6662727886563133, 0.7712694125590817, 0.8546590141796083, 0.9193112761647535]\n",
      "epoch: 77 recall:  0.41661039837947333\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.4091829844699527, 0.5354490209318028, 0.6520931802835922, 0.7645172180958811, 0.8489196488858879, 0.9080013504388926]\n",
      "epoch: 78 recall:  0.4091829844699527\n",
      "best epoch: 65 best recall:  0.4238690074274139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4042876434841323, 0.5337609723160027, 0.6595205941931127, 0.7662052667116813, 0.8517893315327482, 0.912052667116813]\n",
      "epoch: 79 recall:  0.4042876434841323\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.4113774476704929, 0.5320729237002025, 0.6547940580688724, 0.7651924375422012, 0.8433490884537475, 0.9085077650236327]\n",
      "epoch: 80 recall:  0.4113774476704929\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.4012491559756921, 0.5305536799459825, 0.6539500337609723, 0.7662052667116813, 0.8546590141796083, 0.9157663740715732]\n",
      "epoch: 81 recall:  0.4012491559756921\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.40698852126941254, 0.5351114112086428, 0.6612086428089129, 0.7682309250506415, 0.8531397704253882, 0.9181296421336934]\n",
      "epoch: 82 recall:  0.40698852126941254\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.40580688723835245, 0.5217758271438218, 0.6465226198514518, 0.7535449020931803, 0.8431802835921675, 0.9086765698852127]\n",
      "epoch: 83 recall:  0.40580688723835245\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.4049628629304524, 0.5258271438217421, 0.6581701553004726, 0.7579338284942606, 0.8479068197164078, 0.9103646185010128]\n",
      "epoch: 84 recall:  0.4049628629304524\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.3953409858203916, 0.5224510465901417, 0.6487170830519919, 0.761647535449021, 0.849257258609048, 0.912559081701553]\n",
      "epoch: 85 recall:  0.3953409858203916\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.4015867656988521, 0.5317353139770425, 0.6492234976367319, 0.7667116812964213, 0.8551654287643484, 0.9182984469952734]\n",
      "epoch: 86 recall:  0.4015867656988521\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.39787305874409185, 0.5224510465901417, 0.6446657663740716, 0.763504388926401, 0.8524645509790681, 0.912390276839973]\n",
      "epoch: 87 recall:  0.39787305874409185\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.40479405806887236, 0.5310600945307224, 0.6490546927751519, 0.7601282916948008, 0.8509453072248481, 0.9166103983794733]\n",
      "epoch: 88 recall:  0.40479405806887236\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.4091829844699527, 0.5317353139770425, 0.6546252532072924, 0.7602970965563808, 0.8435178933153274, 0.9069885212694125]\n",
      "epoch: 89 recall:  0.4091829844699527\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.39601620526671166, 0.525320729237002, 0.6490546927751519, 0.7591154625253207, 0.8467251856853477, 0.912390276839973]\n",
      "epoch: 90 recall:  0.39601620526671166\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.41677920324105333, 0.5410195813639432, 0.662052667116813, 0.7609723160027009, 0.8475692099932478, 0.9105334233625928]\n",
      "epoch: 91 recall:  0.41677920324105333\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.4073261309925726, 0.5293720459149224, 0.6515867656988521, 0.7606347062795409, 0.8470627954085078, 0.9058068872383525]\n",
      "epoch: 92 recall:  0.4073261309925726\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.3946657663740716, 0.5156988521269412, 0.6450033760972316, 0.7638419986495611, 0.8485820391627279, 0.912052667116813]\n",
      "epoch: 93 recall:  0.3946657663740716\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.40935178933153277, 0.5329169480081026, 0.6564821066846726, 0.7641796083727211, 0.8507765023632681, 0.9103646185010128]\n",
      "epoch: 94 recall:  0.40935178933153277\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.40276839972991224, 0.5234638757596218, 0.6509115462525321, 0.7575962187711006, 0.8462187711006077, 0.9086765698852127]\n",
      "epoch: 95 recall:  0.40276839972991224\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.4140783254557731, 0.5359554355165429, 0.6517555705604321, 0.7604659014179609, 0.8465563808237677, 0.912390276839973]\n",
      "epoch: 96 recall:  0.4140783254557731\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.4085077650236327, 0.5324105334233626, 0.6553004726536125, 0.762491559756921, 0.8430114787305875, 0.9085077650236327]\n",
      "epoch: 97 recall:  0.4085077650236327\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.4042876434841323, 0.5329169480081026, 0.6561444969615124, 0.763673193787981, 0.8546590141796083, 0.9154287643484132]\n",
      "epoch: 98 recall:  0.4042876434841323\n",
      "best epoch: 65 best recall:  0.4238690074274139\n",
      "[0.4024307900067522, 0.5212694125590817, 0.6455097906819717, 0.7577650236326806, 0.850101282916948, 0.9144159351789332]\n",
      "epoch: 99 recall:  0.4024307900067522\n",
      "best epoch: 65 best recall:  0.4238690074274139\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(gpu_id)\n",
    "world_size = int(os.environ.get(\"WORLD_SIZE\", 1))\n",
    "\n",
    "train_tr = dataset.utils.make_transform(\n",
    "    is_train = True, \n",
    "    is_inception = (model == 'bn_inception')\n",
    ")\n",
    "\n",
    "ds_list = {\"CUB\": CUBirds, \"SOP\": SOP, \"Cars\": Cars, \"Inshop\": Inshop_Dataset}\n",
    "ds_class = ds_list[ds]\n",
    "ds_train = ds_class(path, \"train\", train_tr)\n",
    "\n",
    "sampler = UniqueClassSempler(\n",
    "    ds_train.ys, num_samples, local_rank, world_size\n",
    ")\n",
    "dl_train = DataLoader(\n",
    "    dataset=ds_train,\n",
    "    sampler=sampler,\n",
    "    batch_size=bs,\n",
    "    num_workers=workers,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "if model.find('resnet18')+1:\n",
    "    model = Resnet18(embedding_size=emb, pretrained=True, bn_freeze = bn_freeze).cuda().train() \n",
    "elif model.find('resnet34')+1:\n",
    "    model = Resnet34(embedding_size=emb, pretrained=True, bn_freeze = bn_freeze).cuda().train() \n",
    "elif model.find('resnet50')+1:\n",
    "    model = Resnet50(embedding_size=emb, pretrained=True, bn_freeze = bn_freeze).cuda().train() \n",
    "elif model.find('resnet101')+1:\n",
    "    model = Resnet101(embedding_size=emb, pretrained=True, bn_freeze = bn_freeze).cuda().train() \n",
    "loss_f = partial(contrastive_loss, tau=t)\n",
    "\n",
    "get_emb_f = partial(\n",
    "    get_emb,\n",
    "    model=model,\n",
    "    ds=ds_class,\n",
    "    path=path,\n",
    "    num_workers=workers,\n",
    "    world_size=world_size,\n",
    ")\n",
    "if freezer == True:\n",
    "    embedding_param = list(model.model.embedding.parameters())\n",
    "    for param in list(set(model.parameters()).difference(set(embedding_param))):\n",
    "        param.requires_grad = False\n",
    "    optimizer = optim.AdamW(embedding_param, lr=lr)\n",
    "else:\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=lr_decay_step, gamma = lr_decay_gamma)\n",
    "print(\"Training for {} epochs.\".format(ep))\n",
    "\n",
    "r0= evaluate(get_emb_f, ds)\n",
    "print(\"The recall before train: \", r0)\n",
    "\n",
    "losses_list = []\n",
    "best_recall= 0\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(0, ep):\n",
    "    model.train()\n",
    "    if bn_freeze:\n",
    "        modules = model.model.modules()\n",
    "        for m in modules: \n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m.eval()\n",
    "\n",
    "    losses_per_epoch = []\n",
    "    sampler.set_epoch(epoch)\n",
    "    stats_ep = []\n",
    "    for x, y in dl_train:\n",
    "        y = y.view(len(y) // num_samples, num_samples)\n",
    "        assert (y[:, 0] == y[:, -1]).all()\n",
    "        s1 = y[:, 0].tolist()\n",
    "        assert len(set(s1)) == len(s1)\n",
    "\n",
    "        x = x.cuda(non_blocking=True)\n",
    "        e = model(x)\n",
    "        e = e.view(len(x) // num_samples, num_samples, emb)\n",
    "        loss = 0\n",
    "        for i in range(num_samples):\n",
    "            for j in range(num_samples):\n",
    "                if i != j:\n",
    "                    l, st = loss_f(e[:, i], e[:, j])\n",
    "                    loss += l\n",
    "                    stats_ep.append({**st, \"loss\": l.item()})\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 10)\n",
    "        optimizer.step()\n",
    "        \n",
    "    scheduler.step()        \n",
    "    rh= evaluate(get_emb_f, ds)\n",
    "    stats_ep = {k: np.mean([x[k] for x in stats_ep]) for k in stats_ep[0]}\n",
    "    stats_ep = {\"recall\": rh, **stats_ep}\n",
    "    if rh > best_recall :\n",
    "        best_recall = rh\n",
    "        best_epoch = epoch\n",
    "    print(\"epoch:\",epoch,\"recall: \", rh)\n",
    "    print(\"best epoch:\",best_epoch,\"best recall: \", best_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1435d1df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
