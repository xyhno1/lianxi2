{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c1578da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.backends.cudnn as cudnn\n",
    "from apex import amp\n",
    "\n",
    "import os\n",
    "import random\n",
    "import timm\n",
    "import wandb\n",
    "from tqdm import trange\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import PIL\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "from sampler import UniqueClassSempler\n",
    "from proxy_anchor.utils import calc_recall_at_k\n",
    "from proxy_anchor.dataset import CUBirds, SOP, Cars\n",
    "from proxy_anchor.dataset.Inshop import Inshop_Dataset\n",
    "from hyptorch.pmath import dist_matrix\n",
    "import hyptorch.nn as hypnn\n",
    "\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.distributed as dist\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f34eca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf08adb",
   "metadata": {},
   "source": [
    "# 超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e8ec1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num =1\n",
    "path = '/data/xuyunhao/datasets'\n",
    "ds = 'Inshop'\n",
    "num_samples = 2\n",
    "bs = 200\n",
    "\n",
    "lr = 3e-5\n",
    "\n",
    "t = 0.2\n",
    "emb = 128\n",
    "freeze = 0\n",
    "ep = 500\n",
    "hyp_c = 0.1\n",
    "eval_ep = 'r('+str(ep-100)+','+str(ep+10)+',10)'\n",
    "\n",
    "model = 'vit_small_patch16_224'\n",
    "# model = 'dino_vits16'\n",
    "# model = 'deit_small_distilled_patch16_224'\n",
    "\n",
    "save_emb = False\n",
    "emb_name = 'emb'\n",
    "clip_r = 2.3\n",
    "resize = 224\n",
    "crop = 224\n",
    "local_rank = 0\n",
    "save_path = \"/data/xuyunhao/Mixed curvature/result/{}_{}_best_epd_{}_{}_checkout.pth\".format(model,ds,emb,num)\n",
    "load_model = \"/data/xuyunhao/Mixed curvature/result/{}_{}_best_d_{}_1_checkout.pth\".format(model,ds,emb)\n",
    "# load_model = \"/data/xuyunhao/Mixed curvature/result/{}_{}_best_d_{}_{}_checkout.pth\".format(model,ds,emb,num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf0cc79",
   "metadata": {},
   "source": [
    "# 庞加莱模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9e4b1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tensor_dot(x, y):\n",
    "    res = torch.einsum(\"ij,kj->ik\", (x, y))\n",
    "    return res\n",
    "\n",
    "class Artanh(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        x = x.clamp(-1 + 1e-5, 1 - 1e-5)\n",
    "        ctx.save_for_backward(x)\n",
    "        res = (torch.log_(1 + x).sub_(torch.log_(1 - x))).mul_(0.5)\n",
    "        return res\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        (input,) = ctx.saved_tensors\n",
    "        return grad_output / (1 - input ** 2)\n",
    "    \n",
    "def artanh(x):\n",
    "    return Artanh.apply(x)\n",
    "\n",
    "def _mobius_addition_batch(x, y, c):\n",
    "    xy = _tensor_dot(x, y)  # B x C\n",
    "    x2 = x.pow(2).sum(-1, keepdim=True)  # B x 1\n",
    "    y2 = y.pow(2).sum(-1, keepdim=True)  # C x 1\n",
    "    num = 1 + 2 * c * xy + c * y2.permute(1, 0)  # B x C\n",
    "    num = num.unsqueeze(2) * x.unsqueeze(1)\n",
    "    num = num + (1 - c * x2).unsqueeze(2) * y  # B x C x D\n",
    "    denom_part1 = 1 + 2 * c * xy  # B x C\n",
    "    denom_part2 = c ** 2 * x2 * y2.permute(1, 0)\n",
    "    denom = denom_part1 + denom_part2\n",
    "    res = num / (denom.unsqueeze(2) + 1e-5)\n",
    "    return res\n",
    "\n",
    "def _dist_matrix(x, y, c):\n",
    "    sqrt_c = c ** 0.5\n",
    "    return (\n",
    "        2\n",
    "        / sqrt_c\n",
    "        * artanh(sqrt_c * torch.norm(_mobius_addition_batch(-x, y, c=c), dim=-1))\n",
    "    )\n",
    "\n",
    "\n",
    "def dist_matrix(x, y, c=1.0):\n",
    "    c = torch.as_tensor(c).type_as(x)\n",
    "    return _dist_matrix(x, y, c)\n",
    "\n",
    "def tanh(x, clamp=15):\n",
    "    return x.clamp(-clamp, clamp).tanh()\n",
    "\n",
    "def expmap0(u, *, c=1.0):\n",
    "    c = torch.as_tensor(c).type_as(u)\n",
    "    return _expmap0(u, c)\n",
    "\n",
    "def _expmap0(u, c):\n",
    "    sqrt_c = c ** 0.5\n",
    "    u_norm = torch.clamp_min(u.norm(dim=-1, p=2, keepdim=True), 1e-5)\n",
    "    gamma_1 = tanh(sqrt_c * u_norm) * u / (sqrt_c * u_norm)\n",
    "    return gamma_1\n",
    "\n",
    "def project(x, *, c=1.0):\n",
    "    c = torch.as_tensor(c).type_as(x)\n",
    "    return _project(x, c)\n",
    "\n",
    "def _project(x, c):\n",
    "    norm = torch.clamp_min(x.norm(dim=-1, keepdim=True, p=2), 1e-5)\n",
    "    maxnorm = (1 - 1e-3) / (c ** 0.5)\n",
    "    cond = norm > maxnorm\n",
    "    projected = x / norm * maxnorm\n",
    "    return torch.where(cond, projected, x)\n",
    "\n",
    "class ToPoincare(nn.Module):\n",
    "    r\"\"\"\n",
    "    Module which maps points in n-dim Euclidean space\n",
    "    to n-dim Poincare ball\n",
    "    Also implements clipping from https://arxiv.org/pdf/2107.11472.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, c, clip_r=None):\n",
    "        super(ToPoincare, self).__init__()\n",
    "        self.register_parameter(\"xp\", None)\n",
    "\n",
    "        self.c = c\n",
    "        \n",
    "        self.clip_r = clip_r\n",
    "        self.grad_fix = lambda x: x\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.clip_r is not None:\n",
    "            x_norm = torch.norm(x, dim=-1, keepdim=True) + 1e-5\n",
    "            fac =  torch.minimum(\n",
    "                torch.ones_like(x_norm), \n",
    "                self.clip_r / x_norm\n",
    "            )\n",
    "            x = x * fac\n",
    "        return self.grad_fix(project(expmap0(x, c=self.c), c=self.c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3d9514",
   "metadata": {},
   "source": [
    "# 投影超球模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f40a9ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project(x, *, c=1.0):\n",
    "    c = torch.as_tensor(c).type_as(x)\n",
    "    return _project(x, c)\n",
    "\n",
    "def _project(x, c):\n",
    "    norm = torch.clamp_min(x.norm(dim=-1, keepdim=True, p=2), 1e-5)\n",
    "    maxnorm = (1 - 1e-3) / (c ** 0.5)\n",
    "    cond = norm > maxnorm\n",
    "    projected = x / norm * maxnorm\n",
    "    return torch.where(cond, projected, x)\n",
    "\n",
    "def dexp0(u, *, c=1.0):\n",
    "    c = torch.as_tensor(c).type_as(u)\n",
    "    return _dexp0(u, c)\n",
    "\n",
    "def _dexp0(u, c):\n",
    "    sqrt_c = c ** 0.5\n",
    "    u_norm = torch.clamp_min(u.norm(dim=-1, p=2, keepdim=True), 1e-5)\n",
    "    gamma_1 = torch.tan(sqrt_c * u_norm) * u / (sqrt_c * u_norm)\n",
    "    return gamma_1\n",
    "\n",
    "def _dist_matrix_d(x, y, c):\n",
    "    xy =torch.einsum(\"ij,kj->ik\", (x, y))  # B x C\n",
    "    x2 = x.pow(2).sum(-1, keepdim=True)  # B x 1\n",
    "    y2 = y.pow(2).sum(-1, keepdim=True)  # C x 1\n",
    "    sqrt_c = c ** 0.5\n",
    "    num1 = 2*c*(x2+y2.permute(1, 0)-2*xy)+1e-5\n",
    "    num2 = torch.mul((1+c*x2),(1+c*y2.permute(1, 0)))\n",
    "    return (1/sqrt_c * torch.acos(1-num1/num2))\n",
    "\n",
    "\n",
    "def dist_matrix_d(x, y, c=1.0):\n",
    "    c = torch.as_tensor(c).type_as(x)\n",
    "    return _dist_matrix_d(x, y, c)\n",
    "\n",
    "class ToProjection_hypersphere(nn.Module):\n",
    "    def __init__(self, c, clip_r=None):\n",
    "        super(ToProjection_hypersphere, self).__init__()\n",
    "        self.register_parameter(\"xp\", None)\n",
    "        self.c = c\n",
    "        self.clip_r = clip_r\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.clip_r is not None:\n",
    "            x_norm = torch.norm(x, dim=-1, keepdim=True) + 1e-5\n",
    "            fac =  torch.minimum(\n",
    "                torch.ones_like(x_norm), \n",
    "                self.clip_r / x_norm\n",
    "            )\n",
    "            x = x * fac\n",
    "        return project(dexp0(x, c=self.c), c=self.c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ee19da",
   "metadata": {},
   "source": [
    "# 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e4fbf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss_e(e0, e1, tau):\n",
    "    # x0 and x1 - positive pair\n",
    "    # tau - temperature\n",
    "    # hyp_c - hyperbolic curvature, \"0\" enables sphere mode\n",
    "    dist_e = lambda x, y: -torch.cdist(x, y, p=2)\n",
    "    \n",
    "    dist_e0 = dist_e(e0, e0)   \n",
    "    dist_e1 = dist_e(e0, e1)\n",
    "\n",
    "    bsize = e0.shape[0]\n",
    "    target = torch.arange(bsize).cuda()\n",
    "    eye_mask = torch.eye(bsize).cuda() * 1e9\n",
    "    \n",
    "    logits00 = dist_e0 / tau - eye_mask\n",
    "    logits01 = dist_e1 / tau\n",
    "    \n",
    "    logits = torch.cat([logits01, logits00], dim=1)\n",
    "    logits -= logits.max(1, keepdim=True)[0].detach()\n",
    "    loss = F.cross_entropy(logits, target)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0782801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss_p(x0, x1, tau, hyp_c):\n",
    "    # x0 and x1 - positive pair\n",
    "    # tau - temperature\n",
    "    # hyp_c - hyperbolic curvature, \"0\" enables sphere mode\n",
    "\n",
    "    dist_f = lambda x, y: -dist_matrix(x, y, c=hyp_c)\n",
    "    bsize = x0.shape[0]\n",
    "    target = torch.arange(bsize).cuda()\n",
    "    eye_mask = torch.eye(bsize).cuda() * 1e9\n",
    "    logits00 = dist_f(x0, x0) / tau - eye_mask\n",
    "    logits01 = dist_f(x0, x1) / tau\n",
    "    logits = torch.cat([logits01, logits00], dim=1)\n",
    "    logits -= logits.max(1, keepdim=True)[0].detach()\n",
    "    loss = F.cross_entropy(logits, target)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a65cbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss_d(x0, x1, tau, hyp_c):\n",
    "    # x0 and x1 - positive pair\n",
    "    # tau - temperature\n",
    "    # hyp_c - hyperbolic curvature, \"0\" enables sphere mode\n",
    "\n",
    "    dist_f = lambda x, y: -dist_matrix_d(x, y, c=hyp_c)\n",
    "    bsize = x0.shape[0]\n",
    "    target = torch.arange(bsize).cuda()\n",
    "    eye_mask = torch.eye(bsize).cuda() * 1e9\n",
    "    logits00 = dist_f(x0, x0) / tau - eye_mask\n",
    "    logits01 = dist_f(x0, x1) / tau\n",
    "    logits = torch.cat([logits01, logits00], dim=1)\n",
    "    logits -= logits.max(1, keepdim=True)[0].detach()\n",
    "    loss = F.cross_entropy(logits, target)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d35a421",
   "metadata": {},
   "source": [
    "# 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1576317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(model = model, hyp_c = 0.1, emb = 128, clip_r = 2.3, freeze = 0):\n",
    "    if model.startswith(\"dino\"):\n",
    "        body = torch.hub.load(\"facebookresearch/dino:main\", model)\n",
    "    else:\n",
    "        body = timm.create_model(model, pretrained=True)\n",
    "    bdim = 2048 if model == \"resnet50\" else 384  \n",
    "    \n",
    "    Elayer = NormLayer()\n",
    "    embedding_e = nn.Sequential(nn.Linear(bdim, emb), nn.BatchNorm1d(emb))\n",
    "        \n",
    "    Player = ToPoincare(\n",
    "        c=hyp_c,\n",
    "        clip_r=clip_r,\n",
    "    )\n",
    "    embedding_p = nn.Sequential(nn.Linear(bdim, emb),nn.BatchNorm1d(emb), Player)\n",
    "        \n",
    "    Dlayer = ToProjection_hypersphere(\n",
    "        c=hyp_c,\n",
    "        clip_r=clip_r,\n",
    "    )\n",
    "    embedding_d = nn.Sequential(nn.Linear(bdim, emb),nn.BatchNorm1d(emb), Dlayer)\n",
    "\n",
    "    nn.init.constant_(embedding_e[0].bias.data, 0)\n",
    "    nn.init.orthogonal_(embedding_e[0].weight.data)\n",
    "    nn.init.constant_(embedding_p[0].bias.data, 0)\n",
    "    nn.init.orthogonal_(embedding_p[0].weight.data)\n",
    "    nn.init.constant_(embedding_d[0].bias.data, 0)\n",
    "    nn.init.orthogonal_(embedding_d[0].weight.data)\n",
    "    \n",
    "    rm_head(body)\n",
    "    if freeze is not None:\n",
    "        freezer(body,freeze)\n",
    "    model = HeadSwitch(body, embedding_e, embedding_p, embedding_d)\n",
    "    model.cuda().train()\n",
    "    return model\n",
    "    \n",
    "    \n",
    "class HeadSwitch(nn.Module):\n",
    "    def __init__(self, body, embedding_e, embedding_p, embedding_d):\n",
    "        super(HeadSwitch, self).__init__()\n",
    "        self.body = body\n",
    "        self.embedding_e = embedding_e\n",
    "        self.embedding_p = embedding_p\n",
    "        self.embedding_d = embedding_d\n",
    "        self.norm = NormLayer()\n",
    "\n",
    "    def forward(self, x, skip_head=False):\n",
    "        x = self.body(x)\n",
    "        if type(x) == tuple:\n",
    "            x = x[0]\n",
    "        if not skip_head:\n",
    "            x_e = self.embedding_e(x)\n",
    "            x_p = self.embedding_p(x)\n",
    "            x_d = self.embedding_d(x)\n",
    "            return x_e, x_p, x_d\n",
    "        else:\n",
    "            x = self.norm(x)\n",
    "            return x\n",
    "\n",
    "\n",
    "class NormLayer(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return F.normalize(x, p=2, dim=1)\n",
    "\n",
    "\n",
    "def freezer(model, num_block):\n",
    "    def fr(m):\n",
    "        for param in m.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    fr(model.patch_embed)\n",
    "    fr(model.pos_drop)\n",
    "    for i in range(num_block):\n",
    "        fr(model.blocks[i])\n",
    "\n",
    "\n",
    "def rm_head(m):\n",
    "    names = set(x[0] for x in m.named_children())\n",
    "    target = {\"head\", \"fc\", \"head_dist\"}\n",
    "    for x in names & target:\n",
    "        m.add_module(x, nn.Identity())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "418a5df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiSample:\n",
    "    def __init__(self, transform, n=2):\n",
    "        self.transform = transform\n",
    "        self.num = n\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return tuple(self.transform(x) for _ in range(self.num))\n",
    "\n",
    "\n",
    "def evaluate(get_emb_f, ds_name, hyp_c):\n",
    "    if ds_name == \"CUB\" or ds_name == \"Cars\":\n",
    "        emb_head = get_emb_f(ds_type=\"eval\")\n",
    "        recall_head = get_recall(*emb_head, ds_name, hyp_c)\n",
    "    elif ds_name == \"SOP\":\n",
    "        emb_head = get_emb_f(ds_type=\"eval\")\n",
    "        recall_head = get_recall_sop(*emb_head, ds_name, hyp_c)\n",
    "    else:\n",
    "        emb_head_query = get_emb_f(ds_type=\"query\")\n",
    "        emb_head_gal = get_emb_f(ds_type=\"gallery\")\n",
    "        recall_head = get_recall_inshop(*emb_head_query, *emb_head_gal, hyp_c)\n",
    "    return recall_head\n",
    "\n",
    "\n",
    "def get_recall(e, p, d, y, ds_name, hyp_c):\n",
    "    if ds_name == \"CUB\" or ds_name == \"Cars\":\n",
    "        k_list = [1, 2, 4, 8, 16, 32]\n",
    "    elif ds_name == \"SOP\":\n",
    "        k_list = [1, 10, 100, 1000]\n",
    "\n",
    "    dist_m = torch.empty(len(e), len(e), device=\"cuda\")\n",
    "    for i in range(len(e)):\n",
    "        dist_m[i : i + 1] = -torch.cdist(e[i : i + 1], e, p=2)-dist_matrix_d(d[i : i + 1], d, hyp_c)- dist_matrix(p[i : i + 1], p, hyp_c)\n",
    "\n",
    "    y_cur = y[dist_m.topk(1 + max(k_list), largest=True)[1][:, 1:]]\n",
    "    y = y.cpu()\n",
    "    y_cur = y_cur.float().cpu()\n",
    "    recall = [calc_recall_at_k(y, y_cur, k) for k in k_list]\n",
    "    print(recall)\n",
    "    return recall\n",
    "\n",
    "\n",
    "def get_recall_sop(e, p, d, y, ds_name, hyp_c):\n",
    "    y_cur = torch.tensor([]).cuda().int()\n",
    "    number = 1000\n",
    "    k_list = [1, 10, 100, 1000]\n",
    "    for i in range(len(e) // number + 1):\n",
    "        if (i+1)*number > len(e):\n",
    "            e_s = e[i*number:]\n",
    "            p_s = p[i*number:]\n",
    "            d_s = d[i*number:]\n",
    "        else:\n",
    "            e_s = e[i*number: (i+1)*number]\n",
    "            p_s = p[i*number: (i+1)*number]\n",
    "            d_s = d[i*number: (i+1)*number]\n",
    "#         import ipdb;\n",
    "#         ipdb.set_trace()\n",
    "        dist = torch.empty(len(e_s), len(e), device=\"cuda\")\n",
    "        for i in range(len(e_s)):\n",
    "            dist[i : i + 1] = -torch.cdist(e_s[i : i + 1], e, p=2)-dist_matrix_d(d_s[i : i + 1], d, hyp_c)- dist_matrix(p_s[i : i + 1], p, hyp_c)\n",
    "        dist = y[dist.topk(1 + max(k_list), largest=True)[1][:, 1:]]\n",
    "        y_cur = torch.cat([y_cur, dist])\n",
    "    y = y.cpu()\n",
    "    y_cur = y_cur.float().cpu()\n",
    "    recall = [calc_recall_at_k(y, y_cur, k) for k in k_list]\n",
    "    print(recall)\n",
    "    return recall\n",
    "\n",
    "\n",
    "def get_recall_inshop(eq, pq, dq, yq, eg, pg, dg, yg, hyp_c):\n",
    "    dist_m = torch.empty(len(eq), len(eg), device=\"cuda\")\n",
    "    for i in range(len(eq)):\n",
    "        dist_m[i : i + 1] = -torch.cdist(eq[i : i + 1], eg, p=2)-dist_matrix_d(dq[i : i + 1], dg, hyp_c)- dist_matrix(pq[i : i + 1], pg, hyp_c)\n",
    "\n",
    "    def recall_k(cos_sim, query_T, gallery_T, k):\n",
    "        m = len(cos_sim)\n",
    "        match_counter = 0\n",
    "        for i in range(m):\n",
    "            pos_sim = cos_sim[i][gallery_T == query_T[i]]\n",
    "            neg_sim = cos_sim[i][gallery_T != query_T[i]]\n",
    "            thresh = torch.max(pos_sim).item()\n",
    "            if torch.sum(neg_sim > thresh) < k:\n",
    "                match_counter += 1\n",
    "        return match_counter / m\n",
    "\n",
    "    recall = [recall_k(dist_m, yq, yg, k) for k in [1, 10, 20, 30, 40, 50]]\n",
    "    print(recall)\n",
    "    return recall\n",
    "\n",
    "\n",
    "def get_emb(\n",
    "    model,\n",
    "    ds,\n",
    "    path,\n",
    "    mean_std,\n",
    "    resize=224,\n",
    "    crop=224,\n",
    "    ds_type=\"eval\",\n",
    "    world_size=1,\n",
    "    skip_head=False,\n",
    "):\n",
    "    eval_tr = T.Compose(\n",
    "        [\n",
    "            T.Resize(resize, interpolation=PIL.Image.BICUBIC),\n",
    "            T.CenterCrop(crop),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(*mean_std),\n",
    "        ]\n",
    "    )\n",
    "    ds_eval = ds(path, ds_type, eval_tr)\n",
    "    if world_size == 1:\n",
    "        sampler = None\n",
    "    else:\n",
    "        sampler = torch.utils.data.distributed.DistributedSampler(ds_eval)\n",
    "    dl_eval = DataLoader(\n",
    "        dataset=ds_eval,\n",
    "        batch_size=100,\n",
    "        shuffle=False,\n",
    "        num_workers=multiprocessing.cpu_count() // world_size,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        sampler=sampler,\n",
    "    )\n",
    "    model.eval()\n",
    "    if skip_head == True:   \n",
    "        x, y = eval_dataset(model, dl_eval, skip_head)\n",
    "        y = y.cuda()\n",
    "        if world_size > 1:\n",
    "            all_x = [torch.zeros_like(x) for _ in range(world_size)]\n",
    "            all_y = [torch.zeros_like(y) for _ in range(world_size)]\n",
    "            torch.distributed.all_gather(all_x, x)\n",
    "            torch.distributed.all_gather(all_y, y)\n",
    "            x, y = torch.cat(all_x), torch.cat(all_y)\n",
    "        model.train()\n",
    "        return x, y\n",
    "    else:\n",
    "        e, p, d, y = eval_dataset(model, dl_eval, skip_head)\n",
    "        y = y.cuda()\n",
    "        if world_size > 1:\n",
    "            all_e = [torch.zeros_like(e) for _ in range(world_size)]\n",
    "            all_p = [torch.zeros_like(p) for _ in range(world_size)]\n",
    "            all_d = [torch.zeros_like(d) for _ in range(world_size)]\n",
    "            all_y = [torch.zeros_like(y) for _ in range(world_size)]\n",
    "            torch.distributed.all_gather(all_e, e)\n",
    "            torch.distributed.all_gather(all_p, p)\n",
    "            torch.distributed.all_gather(all_d, d)\n",
    "            torch.distributed.all_gather(all_y, y)\n",
    "            e, p, d, y = torch.cat(all_e), torch.cat(all_p), torch.cat(all_d), torch.cat(all_y)\n",
    "        model.train()\n",
    "        return e, p, d, y\n",
    "\n",
    "def eval_dataset(model, dl, skip_head):\n",
    "    all_x, all_xe, all_xp, all_xd, all_y = [], [], [], [], []\n",
    "    for x, y in dl:\n",
    "        with torch.no_grad():\n",
    "            x = x.cuda(non_blocking=True)\n",
    "            e, p, d= model(x, skip_head=skip_head)\n",
    "            all_xe.append(e)\n",
    "            all_xp.append(p)\n",
    "            all_xd.append(d)\n",
    "        all_y.append(y)\n",
    "    return torch.cat(all_xe), torch.cat(all_xp), torch.cat(all_xd), torch.cat(all_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fca7d64",
   "metadata": {},
   "source": [
    "# 主函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27aa772",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxuyunhao\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/xuyunhao/Mixed curvature/wandb/run-20230418_174044-1ivkt82y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/xuyunhao/hyp_metric/runs/1ivkt82y\" target=\"_blank\">scarlet-river-492</a></strong> to <a href=\"https://wandb.ai/xuyunhao/hyp_metric\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_path: /data/xuyunhao/Mixed curvature/result/vit_small_patch16_224_Inshop_best_epd_128_1_checkout.pth\n",
      "load_model: /data/xuyunhao/Mixed curvature/result/vit_small_patch16_224_Inshop_best_d_128_1_checkout.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                             | 0/500 [00:00<?, ?it/s]/data/xuyunhao/.conda/envs/pytorch/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
      "  0%|                                                 | 1/500 [01:51<15:28:22, 111.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9108876072584048, 0.9792516528344353, 0.9857926571951048, 0.9879729919819946, 0.9893093262062175, 0.9905049936699958]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▉                                                  | 9/500 [04:36<3:02:36, 22.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9143339428892953, 0.9819243212828809, 0.9869883246588831, 0.9895906597271065, 0.9909973273315515, 0.9921226614151076]\n",
      "save model........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▉                                                | 19/500 [09:26<2:52:21, 21.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9165142776761851, 0.9815023210015473, 0.988043325362217, 0.990293993529329, 0.9912786608524405, 0.9921226614151076]\n",
      "save model........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▉                                               | 29/500 [14:14<2:49:08, 21.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9189056126037417, 0.9829793219862146, 0.988043325362217, 0.9898016598677732, 0.9915599943733295, 0.9921929947953299]\n",
      "save model........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████                                              | 40/500 [20:47<5:53:45, 46.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9161626107750739, 0.9822056548037699, 0.988043325362217, 0.989731326487551, 0.9914896609931073, 0.9924039949359966]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████                                             | 50/500 [25:35<5:46:19, 46.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9166549444366296, 0.9826979884653256, 0.9878323252215502, 0.9903643269095512, 0.9918413278942186, 0.9929666619777746]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████                                            | 60/500 [30:23<5:39:27, 46.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9150372766915178, 0.9826276550851034, 0.9883949922633282, 0.9903643269095512, 0.9913489942326629, 0.9927556618371078]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████                                           | 70/500 [35:10<5:29:42, 46.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9149669433112956, 0.9810099873399916, 0.9874806583204389, 0.990575327050218, 0.9922633281755521, 0.9932479954986637]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████                                          | 80/500 [40:09<5:46:01, 49.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9173582782388522, 0.9824869883246589, 0.9879026586017724, 0.989731326487551, 0.9912786608524405, 0.9924039949359966]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████▉                                         | 89/500 [43:13<2:27:11, 21.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9202419468279646, 0.9818539879026587, 0.9872696581797721, 0.9896609931073287, 0.9910676607117738, 0.9918413278942186]\n",
      "save model........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████                                         | 90/500 [45:00<5:22:01, 47.12s/it]wandb: Network error (ReadTimeout), entering retry loop.\n",
      " 20%|█████████▊                                       | 100/500 [49:50<5:13:08, 46.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9129976086650724, 0.9813616542411028, 0.9873399915599944, 0.989449992966662, 0.990856660571107, 0.9919819946546631]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████▊                                      | 110/500 [54:35<4:57:41, 45.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9177099451399634, 0.9822759881839921, 0.9871993247995499, 0.9896609931073287, 0.9913489942326629, 0.9921929947953299]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████████▊                                     | 120/500 [59:23<4:52:42, 46.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91510761007174, 0.9821353214235476, 0.9869179912786609, 0.989449992966662, 0.9912786608524405, 0.9922633281755521]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████▏                                  | 130/500 [1:04:11<4:47:47, 46.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9179912786608524, 0.9819946546631031, 0.9868476578984386, 0.9893796595864397, 0.9907863271908848, 0.9916303277535519]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|█████████████▏                                 | 140/500 [1:08:56<4:36:25, 46.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.915388943592629, 0.9812209874806583, 0.9871993247995499, 0.9900829933886622, 0.9909973273315515, 0.9919116612744409]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████                                 | 150/500 [1:13:45<4:31:35, 46.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9133492755661837, 0.9812209874806583, 0.9864959909973273, 0.9890983260655507, 0.990856660571107, 0.9920523280348854]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███████████████                                | 160/500 [1:18:33<4:24:07, 46.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9156702771135181, 0.9811506541004361, 0.9863553242368829, 0.9891686594457729, 0.9900829933886622, 0.9914193276128851]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███████████████▉                               | 170/500 [1:23:22<4:17:09, 46.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9172176114784076, 0.9815023210015473, 0.9867069911379941, 0.9890279926853285, 0.9913489942326629, 0.9927556618371078]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|████████████████▉                              | 180/500 [1:28:12<4:09:45, 46.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9136306090870727, 0.9815023210015473, 0.9871993247995499, 0.989449992966662, 0.9907863271908848, 0.9919116612744409]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|█████████████████▊                             | 190/500 [1:33:07<4:08:26, 48.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.918131945421297, 0.9831903221268814, 0.9873399915599944, 0.9895203263468842, 0.9909973273315515, 0.9918413278942186]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████▊                            | 200/500 [1:37:54<3:51:31, 46.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9184836123224082, 0.9824869883246589, 0.9874103249402166, 0.9891686594457729, 0.9904346602897736, 0.9914896609931073]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████████████████▋                           | 210/500 [1:42:43<3:44:28, 46.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9162329441552961, 0.9824166549444366, 0.9881136587424392, 0.9905049936699958, 0.9917709945139963, 0.9926149950766634]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████████████████████▋                          | 220/500 [1:47:31<3:35:26, 46.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9172176114784076, 0.9825573217048811, 0.9881839921226614, 0.9911379940919961, 0.9926853284568856, 0.9938809959206639]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████████▌                         | 230/500 [1:52:20<3:31:23, 46.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9155296103530736, 0.9817133211422141, 0.9868476578984386, 0.9893796595864397, 0.9907863271908848, 0.9919116612744409]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████████▊                         | 232/500 [1:53:00<2:28:26, 33.23s/it]wandb: Network error (ReadTimeout), entering retry loop.\n",
      " 48%|██████████████████████▌                        | 240/500 [1:57:09<3:21:46, 46.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9189056126037417, 0.9832606555071036, 0.9879729919819946, 0.9905049936699958, 0.9919116612744409, 0.9924743283162188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████████████▏                       | 247/500 [1:59:33<1:36:33, 22.90s/it]"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] =  \"5,6\"\n",
    "if local_rank == 0:\n",
    "    wandb.init(project=\"hyp_metric\")\n",
    "\n",
    "world_size = int(os.environ.get(\"WORLD_SIZE\", 1))\n",
    "    \n",
    "if model.startswith(\"vit\"):\n",
    "    mean_std = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
    "else:\n",
    "    mean_std = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n",
    "train_tr = T.Compose(\n",
    "    [\n",
    "        T.RandomResizedCrop(\n",
    "            crop, scale=(0.2, 1.0), interpolation=InterpolationMode.BICUBIC\n",
    "        ),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(*mean_std),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ds_list = {\"CUB\": CUBirds, \"SOP\": SOP, \"Cars\": Cars, \"Inshop\": Inshop_Dataset}\n",
    "ds_class = ds_list[ds]\n",
    "ds_train = ds_class(path, \"train\", train_tr)\n",
    "assert len(ds_train.ys) * num_samples >= bs * world_size\n",
    "sampler = UniqueClassSempler(\n",
    "    ds_train.ys, num_samples, local_rank, world_size\n",
    ")\n",
    "dl_train = DataLoader(\n",
    "    dataset=ds_train,\n",
    "    sampler=sampler,\n",
    "    batch_size=bs,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "model = init_model(model = model, hyp_c = hyp_c, emb = emb, clip_r = clip_r, freeze = freeze)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "model = nn.DataParallel(model)\n",
    "model.load_state_dict(torch.load(load_model), False)\n",
    "\n",
    "\n",
    "loss_e = partial(contrastive_loss_e, tau=t)\n",
    "loss_p = partial(contrastive_loss_p, tau=t, hyp_c= hyp_c)\n",
    "loss_d = partial(contrastive_loss_d, tau=t, hyp_c= hyp_c)\n",
    "\n",
    "get_emb_f = partial(\n",
    "    get_emb,\n",
    "    model=model,\n",
    "    ds=ds_class,\n",
    "    path=path,\n",
    "    mean_std=mean_std,\n",
    "    world_size=world_size,\n",
    "    resize=resize,\n",
    "    crop=crop,\n",
    ")\n",
    "\n",
    "eval_ep = eval(eval_ep.replace(\"r\", \"list(range\").replace(\")\", \"))\")) \n",
    "\n",
    "cudnn.benchmark = True\n",
    "all_rh = []\n",
    "best_rh = []\n",
    "best_ep = 0\n",
    "lower_cnt = 0\n",
    "\n",
    "print(\"save_path:\", save_path)\n",
    "print(\"load_model:\", load_model)\n",
    "\n",
    "for ep in trange(ep):\n",
    "    sampler.set_epoch(ep)\n",
    "    stats_ep = []\n",
    "    for x, y in dl_train:\n",
    "        y = y.view(len(y) // num_samples, num_samples)\n",
    "        assert (y[:, 0] == y[:, -1]).all()\n",
    "        s = y[:, 0].tolist()\n",
    "        assert len(set(s)) == len(s)\n",
    "\n",
    "        x = x.cuda(non_blocking=True)\n",
    "        e, p, d = model(x)\n",
    "        e = e.view(len(x) // num_samples, num_samples, emb)\n",
    "        p = p.view(len(x) // num_samples, num_samples, emb)\n",
    "        d = d.view(len(x) // num_samples, num_samples, emb)\n",
    "        if world_size > 1:\n",
    "            with torch.no_grad():\n",
    "                all_e = [torch.zeros_like(e) for _ in range(world_size)]\n",
    "                torch.distributed.all_gather(all_e, e)\n",
    "            all_e[local_rank] = e\n",
    "            e = torch.cat(all_e)\n",
    "            with torch.no_grad():\n",
    "                all_p = [torch.zeros_like(p) for _ in range(world_size)]\n",
    "                torch.distributed.all_gather(all_p, p)\n",
    "            all_p[local_rank] = p\n",
    "            p = torch.cat(all_p)\n",
    "            with torch.no_grad():\n",
    "                all_d = [torch.zeros_like(d) for _ in range(world_size)]\n",
    "                torch.distributed.all_gather(all_d, d)\n",
    "            all_d[local_rank] = d\n",
    "            d = torch.cat(all_d)\n",
    "        loss = 0\n",
    "        for i in range(num_samples):\n",
    "            for j in range(num_samples):\n",
    "                if i != j:\n",
    "                    l= loss_e(e[:, i], e[:, j])+loss_p(p[:, i], p[:, j])+loss_d(d[:, i], d[:, j])\n",
    "                    loss += l\n",
    "                    stats_ep.append({\"loss\": l.item()})\n",
    "                    \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), 3)\n",
    "        optimizer.step()\n",
    "        \n",
    "#     if (ep + 1) in eval_ep:\n",
    "#         rh= evaluate(get_emb_f, ds, hyp_c)\n",
    "\n",
    "    if (ep+1) % 10 == 0 or ep == 0:\n",
    "        rh = evaluate(get_emb_f, ds, hyp_c)\n",
    "        all_rh.append(rh)\n",
    "        if ep == 0:\n",
    "            best_rh = rh\n",
    "        else:\n",
    "            if isinstance(rh, list):\n",
    "                if rh[0] >= best_rh[0]:\n",
    "                    lower_cnt = 0\n",
    "                    best_rh = rh\n",
    "                    best_ep = ep\n",
    "                    print(\"save model........\")\n",
    "                    torch.save(model.state_dict(), save_path)\n",
    "                else:\n",
    "                    lower_cnt += 1\n",
    "            else:\n",
    "                if rh >= best_rh:\n",
    "                    lower_cnt = 0\n",
    "                    best_rh = rh\n",
    "                    best_ep = ep\n",
    "                    print(\"save model........\")\n",
    "                    torch.save(model.state_dict(), save_path)\n",
    "                else:\n",
    "                    lower_cnt += 1\n",
    "    \n",
    "    if lower_cnt >= 20:\n",
    "        break\n",
    "        \n",
    "    if local_rank == 0:\n",
    "        stats_ep = {k: np.mean([x[k] for x in stats_ep]) for k in stats_ep[0]}\n",
    "        if (ep + 1) in eval_ep:\n",
    "            stats_ep = {\"recall\": rh, **stats_ep}\n",
    "        wandb.log({**stats_ep, \"ep\": ep})\n",
    "        \n",
    "print(\"best:\", best_ep + 1, best_rh)\n",
    "print(\"save_path:\", save_path)\n",
    "print(\"load_model:\", load_model)\n",
    "        \n",
    "if save_emb:\n",
    "    ds_type = \"gallery\" if ds == \"Inshop\" else \"eval\"\n",
    "    x, y = get_emb_f(ds_type=ds_type)\n",
    "    x, y = x.float().cpu(), y.long().cpu()\n",
    "    torch.save((x, y), path + \"/\" + emb_name + \"_eval.pt\")\n",
    "\n",
    "    x, y = get_emb_f(ds_type=\"train\")\n",
    "    x, y = x.float().cpu(), y.long().cpu()\n",
    "    torch.save((x, y), path + \"/\" + emb_name + \"_train.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffb4507",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
